{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54130331",
   "metadata": {},
   "source": [
    "# Main ingredients\n",
    "\n",
    "- Dataset \n",
    "- Model\n",
    "- Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179a04b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset\n",
    "From raw data you'll need to create a dataset. This creation may include this steps:\n",
    "\n",
    "- Preprocessing\n",
    "- Augmentation\n",
    "- Splitting\n",
    "- Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c6509",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Preprocessing\n",
    "- Removing unnecessary or distracting data\n",
    "- Organizing data\n",
    "- Cropping\n",
    "- Correcting the dynamic range\n",
    "- Normalization\n",
    "\n",
    "### Augmentation\n",
    "- Adding noise\n",
    "- Flipping\n",
    "- Rotating\n",
    "- Cropping\n",
    "- Scaling\n",
    "- Blurring\n",
    "- Geometric distortions\n",
    "\n",
    "### Splitting\n",
    "Splitting data into train and test sets. So that you train on the test set and keep a part of the data for validation. This is done to measure the performance of the model on unseen data. \n",
    "A Useful tool for this is ```sklearn.model_selection.train_test_split```\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "Splits the data into 80% for training and 20% for testing.\n",
    "### Loading\n",
    "Loading the data from the dataset, feeding it into the model and training it in an efficient way. PyTorch DataLoader can be a helpful tool for this. You need to have a dataloader that can load data in batches. This is done to avoid memory issues and to speed up the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eef985",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "- Define the architecture of the model\n",
    "- Define the loss function\n",
    "- Define the optimizer\n",
    "- Define the scheduler\n",
    "- Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51867f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Trainer\n",
    "A script that loops through data in batches, forward passes it through the model, computes the loss, computes the gradients, and updates the model parameters by backpropagating the gradients.\n",
    "```python\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True , num_workers=8)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "```\n",
    "One can log the loss and other metrics using `Weights & Biases` or `TensorBoard` to monitor the training process.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
